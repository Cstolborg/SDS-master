---
title: "Workshop: Exploring the InsideAirBnB dataset"
author: "Daniel S. Hain (dsh@business.aau.dk)"
date: "Updated `r format(Sys.time(), '%B %d, %Y')`"
output:
  html_notebook:
    code_folding: show
    df_print: paged
    toc: true
    toc_depth: 2
    toc_float:
      collapsed: false
    theme: flatly
---

```{r setup, include=FALSE}
# Knitr options
### Generic preamble
Sys.setenv(LANG = "en") # For english language
options(scipen = 5) # To deactivate annoying scientific number notation

# rm(list=ls()); graphics.off() # get rid of everything in the workspace
if (!require("knitr")) install.packages("knitr"); library(knitr) # For display of the markdown

### Knitr options
knitr::opts_chunk$set(warning=FALSE,
                     message=FALSE,
                     fig.align="center"
                     )
```

## Preamble

```{r}
# Clear workspace
rm(list=ls()); graphics.off() 
```

```{r}
### Load packages
library(tidyverse) # Collection of all the good stuff like dplyr, ggplot2 ect.
library(magrittr) # For extra-piping operators (eg. %<>%)
library(skimr) # For nice data summaries
```


# The InsideAirBnB data

## Instroduction


* The data is sourced from the [**Inside Airbnb**](http://insideairbnb.com/get-the-data.html) which hosts publicly available data from the Airbnb site.
* Interactive visualizations are provided [here](http://insideairbnb.com/copenhagen/?neighbourhood=&filterEntireHomes=false&filterHighlyAvailable=false&filterRecentReviews=false&filterMultiListings=false)

The dataset comprises of three main tables:

* `listings` - Detailed listings data showing 96 atttributes for each of the listings. Some of the attributes which are intuitivly interesting are: `price` (continuous), `longitude` (continuous), `latitude` (continuous), `listing_type` (categorical), `is_superhost` (categorical), `neighbourhood` (categorical), `ratings` (continuous) among others.
* `reviews` - Detailed reviews given by the guests with 6 attributes. Key attributes include `date` (datetime), `listing_id` (discrete), `reviewer_id` (discrete) and `comment` (textual).
* `calendar` - Provides details about booking for the next year by listing. Four attributes in total including `listing_id` (discrete), `date` (datetime), `available` (categorical) and `price` (continuous).

## Load data

```{r}
listings <- read_csv('http://data.insideairbnb.com/denmark/hovedstaden/copenhagen/2020-06-26/data/listings.csv.gz')
listings %>% glimpse()
```

```{r}
#calendar <- read_csv('http://data.insideairbnb.com/denmark/hovedstaden/copenhagen/2020-06-26/data/calendar.csv.gz')
#calendar %>% glimpse()
```

```{r}
reviews <- read_csv('http://data.insideairbnb.com/denmark/hovedstaden/copenhagen/2020-06-26/data/reviews.csv.gz')
reviews %>% glimpse()
```

```{r}
# # And the summary plus geodata
# summaries_listings <- read_csv('http://data.insideairbnb.com/denmark/hovedstaden/copenhagen/2020-06-26/visualisations/listings.csv')
# summaries_reviews <- read_csv('http://data.insideairbnb.com/denmark/hovedstaden/copenhagen/2020-06-26/visualisations/reviews.csv')
# summaries_neighbourhoods <- read_csv('http://data.insideairbnb.com/denmark/hovedstaden/copenhagen/2020-06-26/visualisations/neighbourhoods.csv')
```
```{r}
# The geodat of the hoods comes as a geojson, so we need the right package to load it
library(geojsonio)
neighbourhoods_geojson <- geojson_read( 'http://data.insideairbnb.com/denmark/hovedstaden/copenhagen/2020-06-26/visualisations/neighbourhoods.geojson',  what = "sp")
```

# Problem 1: Professional host

```{r}
listings %>%
  count(host_id, sort = TRUE)
```

```{r}
listings %>%
  filter(host_id == 187610263) %>%
  count(neighbourhood_cleansed, sort = TRUE)
```

```{r}
listings %<>%
  mutate(price = price %>% parse_number(),
         price_sqf = price / square_feet) 
```

```{r}
listings %<>%
  group_by(host_id) %>%
  mutate(host_professional = n() >= 5) %>%
  ungroup()
```

```{r}
listings %>%
  group_by(host_professional) %>%
  summarise(review = review_scores_rating %>% mean(na.rm = TRUE),
            price = price %>% mean(na.rm = TRUE))
```

```{r}
listings %>%
  group_by(neighbourhood_cleansed, host_professional) %>%
  summarise(review = review_scores_rating %>% mean(na.rm = TRUE)) %>%
  pivot_wider(names_from = host_professional, values_from = review)
```


# Description & Satisfaction

```{r}
listings %<>%
  mutate(desc_lenght = description %>% str_count('\\w+')) %>%
  mutate(desc_long =  percent_rank(desc_lenght) > 0.9 )
```

```{r}
listings %>%
  group_by(desc_long) %>%
  summarise(review = review_scores_rating %>% mean(na.rm =TRUE))
```









# Inspecting & Tidying data

## Basic formating

```{r}
listings %>% skim()
```

```{r}
listings %<>%
    mutate(across(is_character, ~ifelse(.x == "", NA, .x)))
```


## Misssing data

```{r}
library(VIM)
```

```{r}
listings %>% 
  select(host_is_superhost, review_scores_rating, host_response_time, name, host_since,zipcode) %>%
  aggr(numbers = TRUE, prop = c(TRUE, FALSE))
```

# Best party place

```{r}
listings %<>% 
  mutate(party_place = accommodates >= 10) 
```

```{r}
listings %>% 
  filter(party_place == TRUE) %>%
  group_by(neighbourhood_cleansed) %>%
  summarize(n = n(),
         review = review_scores_rating %>% mean(na.rm = TRUE),
         price = price %>% mean(na.rm = TRUE) ) %>%
  arrange(desc(n))
```


# EDA























# DataViz

# Geoplotting

```{r}
library(leaflet)
```

```{r}
listings %>% leaflet() %>%
  addTiles() %>%
  addMarkers(~longitude, ~latitude,
             labelOptions = labelOptions(noHide = F),
             clusterOptions = markerClusterOptions(),
             popup = paste0("<b> Name: </b>", listings$name, 
                            "<br/><b> Host Name: </b>", listings$host_name, 
                            "<br> <b> Price: </b>", listings$price, 
                            "<br/><b> Room Type: </b>", listings$room_type, 
                            "<br/><b> Property Type: </b>", listings$property_type
                 )) %>% 
#  setView(-74.00, 40.71, zoom = 12) %>%
  addProviderTiles("CartoDB.Positron")
```

```{r}
# I need to fortify the data AND keep trace of the commune code! (Takes ~2 minutes)
library(broom)
neighbourhoods_tidy <-  neighbourhoods_geojson %>%
  tidy(region = "neighbourhood")
```

```{r}
neighbourhoods_tidy %>% glimpse()
```

```{r}
neighbourhoods_tidy %>%
  ggplot(aes(x = long, y = lat, group = group)) +
  geom_polygon() +
  theme_void() +
  coord_map()
```
```{r}
neighborhood_agg <- listings %>%
  group_by(neighbourhood_cleansed) %>%
  summarise(n = n(),
            price_mean = price %>% mean(na.rm = TRUE),
            review_mean = review_scores_rating %>% mean(na.rm = TRUE))
  
```

```{r}
neighbourhoods_tidy %<>%
  left_join(neighborhood_agg, by = c('id' = 'neighbourhood_cleansed'))
```

```{r}
neighbourhoods_tidy %>%
  ggplot(aes(x = long, y = lat, group = group, fill = n)) +
  geom_polygon() +
  theme_void() +
  coord_map()
```

```{r}
neighbourhoods_tidy %>%
  ggplot(aes(x = long, y = lat, group = group, fill = price_mean)) +
  geom_polygon() +
  theme_void() +
  coord_map()
```

```{r}
neighbourhoods_tidy %>%
  ggplot(aes(x = long, y = lat, group = group, fill = review_mean)) +
  geom_polygon() +
  theme_void() +
  coord_map()
```

# Subervised ML

## Data cleaning

Inspect again...

```{r}
listings %>% glimpse()
```

```{r}
data <- listings %>%
  mutate(price = price + parse_number(cleaning_fee)) %>%
  filter(number_of_reviews >= 2)
```


```{r}
data  %<>% 
  select(price, review_scores_rating, neighbourhood_cleansed, accommodates, room_type, bathrooms,is_business_travel_ready, 
         number_of_reviews, cancellation_policy, 
         host_is_superhost, host_identity_verified, bedrooms) %>%
  rename(y = price) %>%
  relocate(y, everything()) %>%
  drop_na()
```

```{r}
data %>% count(neighbourhood_cleansed, sort = TRUE)
```

```{r}
data %>% count(room_type, sort = TRUE)
```

```{r}
data %<>%
  filter(!(room_type %in% c('Shared room', 'Hotel room')))
```

```{r}
data %<>%
  filter(percent_rank(y) <0.95)
```

```{r}
data %>%
  skim()
```

```{r}
#library(GGally)
#â‚¬data %>% ggpairs(aes(alpha = 0.3))  
```

## Preprocessing

```{r}
library(tidymodels)
```

### Train and test split

```{r}
data_split <- initial_split(data, prop = 0.75, strata = y)

data_train <- data_split  %>%  training()
data_test <- data_split %>% testing()
```

```{r}
data_recipe <- data_train %>%
  recipe(y ~.) %>%
  step_center(all_numeric(), -all_outcomes()) %>%
  step_scale(all_numeric(), -all_outcomes()) %>%
  step_dummy(all_nominal(), one_hot = FALSE) 
```


### Models

```{r}
model_lm <- linear_reg(mode = 'regression') %>%
  set_engine('lm') 
```

```{r}
model_xg <- boost_tree(mode = 'regression', 
                       trees = 100,
                       mtry = tune(), 
                       min_n = tune(), 
                       tree_depth = tune(), 
                       learn_rate = tune()
                       ) %>%
  set_engine("xgboost") 
```

### Workflows
```{r}
workflow_general <- workflow() %>%
  add_recipe(data_recipe) 

workflow_lm <- workflow_general %>%
  add_model(model_lm)

workflow_xg <- workflow_general %>%
  add_model(model_xg)
```

### Resampling

```{r}
data_resample <- data_train %>% 
  vfold_cv(strata = y,
           v = 3,
           repeats = 2)
```

### Hyperparameter Tuning

```{r}
tune_xg <-
  tune_grid(
    workflow_xg,
    resamples = data_resample,
    grid = 10
  )
```

```{r}
tune_xg %>% autoplot()
```

```{r}
best_param_xg <- tune_xg %>% select_best(metric = 'rmse')
best_param_xg
```

```{r}
tune_xg %>% show_best(metric = 'rmse', n = 1)
```

### Fit models with tuned hyperparameters

```{r}
workflow_final_xg <- workflow_xg %>%
  finalize_workflow(parameters = best_param_xg)
```

```{r}
fit_lm <- workflow_lm %>%
  fit(data_train)

fit_xg <- workflow_final_xg %>%
  fit(data_train)
```

### Predict

```{r}
pred_collected <- tibble(
  truth = data_test %>% pull(y),
  base = mean(truth),
  lm = fit_lm %>% predict(new_data = data_test) %>% pull(.pred),
  xg = fit_xg %>% predict(new_data = data_test) %>% pull(.pred),
  ) %>% 
  pivot_longer(cols = -truth,
               names_to = 'model',
               values_to = '.pred')
```

### Evaluate

```{r}
pred_collected %>%
  group_by(model) %>%
  rmse(truth = truth, estimate = .pred) %>%
  select(model, .estimate) %>%
  arrange(.estimate)
```

```{r}
pred_collected %>%
  group_by(model) %>%
  rsq(truth = truth, estimate = .pred) %>%
  select(model, .estimate) %>%
  arrange(.estimate)
```

```{r}
pred_collected %>%
  ggplot(aes(x = truth, y = .pred, color = model)) +
  geom_abline(lty = 2, color = "gray80", size = 1.5) +
  geom_point(alpha = 0.5) +
  labs(
    x = "Truth",
    y = "Predicted price",
    color = "Type of model"
  )
```

```{r}
fit_lm %>% 
#  pluck(".workflow", 1) %>%   
  pull_workflow_fit() %>% 
  vip::vip(num_features = 10)
```

```{r}
fit_xg %>% 
#  pluck(".workflow", 1) %>%   
  pull_workflow_fit() %>% 
  vip::vip(num_features = 10)
```
